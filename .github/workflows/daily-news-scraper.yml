name: Daily Regulatory News Scraper

on:
  schedule:
    # Runs daily at 6:00 AM UTC (adjust to your preferred time)
    - cron: '*/2 * * * *'
  
  # Allows manual trigger from GitHub Actions tab
  workflow_dispatch:

jobs:
  scrape-and-send-emails:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: Cache pip packages
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: Run news scraper and send emails
        env:
          DATABASE_URL: ${{ secrets.postgresql://app_user:Nxy9NrSa8vaskK1lqnSZnc82F1U5RBJe@dpg-d4iouuidbo4c73bto340-a.oregon-postgres.render.com/data_source_db }}
          EMAIL_USER: ${{ secrets.stellaisokpehi21@gmail.com }}
          EMAIL_PASSWORD: ${{ secrets.tnfb wvtj gjcg ednn }}
          SMTP_SERVER: ${{ secrets.smtp.gmail.com }}
          SMTP_PORT: ${{ secrets.587 }}
        run: |
          python scheduler.py
      
      - name: Log completion
        if: success()
        run: echo "✅ News scraper completed successfully at $(date)"
      
      - name: Log failure
        if: failure()
        run: echo "❌ News scraper failed. Check logs above."