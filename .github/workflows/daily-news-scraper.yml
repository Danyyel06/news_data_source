name: Daily Regulatory News Scraper

on:
  schedule:
    # Runs daily at 6:00 AM UTC (adjust to your preferred time)
    - cron: '0 6 * * *'
  
  # Allows manual trigger from GitHub Actions tab
  workflow_dispatch:

jobs:
  scrape-and-send-emails:
    runs-on: ubuntu-latest
    
    steps:
      - name: Checkout repository
        uses: actions/checkout@v3
      
      - name: Set up Python
        uses: actions/setup-python@v4
        with:
          python-version: '3.11'
      
      - name: Cache pip packages
        uses: actions/cache@v3
        with:
          path: ~/.cache/pip
          key: ${{ runner.os }}-pip-${{ hashFiles('**/requirements.txt') }}
          restore-keys: |
            ${{ runner.os }}-pip-
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install -r requirements.txt
      
      - name: Run news scraper and send emails
        env:
          DATABASE_URL: ${{ secrets.DATABASE_URL }}
          EMAIL_USER: ${{ secrets.EMAIL_USER }}
          EMAIL_PASSWORD: ${{ secrets.EMAIL_PASSWORD }}
          SMTP_SERVER: ${{ secrets.SMTP_SERVER }}
          SMTP_PORT: ${{ secrets.SMTP_PORT }}
        run: |
          python scheduler.py
      
      - name: Log completion
        if: success()
        run: echo "✅ News scraper completed successfully at $(date)"
      
      - name: Log failure
        if: failure()
        run: echo "❌ News scraper failed. Check logs above."